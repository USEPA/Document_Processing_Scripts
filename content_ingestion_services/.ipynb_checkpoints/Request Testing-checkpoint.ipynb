{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Hi this is an email from Mike to Jim talking about how we should get those records down to region 5 and then send them to region 10. Thanks!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "          \"service\": 'records',\n",
    "          \"parameters\": {\n",
    "            \"input\": {},\n",
    "            \"output\": {\n",
    "              \"confidence_threshold\": 0.4\n",
    "            },\n",
    "            \"mllib\": {\n",
    "              \"gpu\": False\n",
    "            }\n",
    "          },\n",
    "          \"data\": [sample]\n",
    "          \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_detect = 'https://ecms-cis-deepdetect-api-prod.edap-cluster.com/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(deep_detect,json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': {'code': 200, 'msg': 'OK'},\n",
       " 'head': {'method': '/predict', 'service': 'records', 'time': 38.0},\n",
       " 'body': {'predictions': [{'classes': [{'prob': 0.5468838214874268,\n",
       "      'last': True,\n",
       "      'cat': '401-1006-b'}],\n",
       "    'uri': '0'}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_data = {\n",
    "          \"text\":  sample\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_endpoint = 'https://ecms-cis-nlpbuddy.edap-cluster.com/api/analyze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = requests.post(nlp_endpoint, json=nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nlp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc = open('Project Overview.docx', 'rb')\n",
    "files = {'file': sample_doc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': <_io.BufferedReader name='Project Overview.docx'>}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"accept\": \"text/plain\"\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tika_endpoint = 'https://ecms-cis-tika-prod.edap-cluster.com/tika/form'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tika_req = requests.post(tika_endpoint, files=files, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tika_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overview of ECMS Projects\\nEZDesktop Application\\n[bookmark: _GoBack]The EZDesktop application is used by EPA employees to flag documents as official EPA records. The current iteration of the application is very simple, and allows employees to upload records without any additional metadata. This is a challenge for records management, since each record must be assigned to an official record schedule. Ideally, the employee uploading the document would provide a record schedule, allowing for proper retention and retrieval of the record. \\nThe goal of this project is to update the EZDesktop application so that it requires users to provide a record at the time the document is uploaded. This is beneficial for records classification, but makes EZDesktop significantly less easy for users. Records classification is not always easy Ã¢\\x80\\x93 there are over 500 different record schedules, each with their own specific requirements. There is a risk that employees will give records an incorrect schedule, or will be discouraged from submitting valid records because they dread the process of classifying the record. To ease this transition, EZDesktop will provide the user with suggested record classifications based on machine learning. It will also provide utilities for saving commonly used record schedules and searching record schedules by terms in the record schedule description, and using keywords identified by EPA records and language experts. \\nEZDesktop Outlook Integration\\nIn addition to the EZDesktop application, we would like to develop an integration with Outlook for flagging emails as records. This will have some of the same functionality as the Desktop app, but there will be some differences since only email records can be flagged within Outlook. General emails are already retained under the Capstone project, so emails flagged within the plugin must require a more strict record schedule in order to qualify for entry into ECMS. \\nUnderstand and Classify Existing Records\\nECMS currently holds roughly 30 million records. The majority of these records do not have an assigned record schedule. ECMS is unable to dispose of records which are not classified to a record schedule, resulting in the unnecessary retention of many records. Using machine learning, we may be able to roughly predict the appropriate record schedule for a document. By applying the model to the full corpus of documents, we can focus our attention on records which the model is confident we no longer need to retain, because they have already been held past the requirement of their predicted record schedule. If we become confident enough in the model, we may choose for a portion of these documents to be removed automatically, reducing the footprint of ECMS.\\nUsing any automated method comes with risks. We will use cross validation to estimate the accuracy of our model. We will compare the estimated error rate of the model with the human error rate to understand how the risk of misclassification by the model compares with the risk of misclassification by EPA employees. This information can be used by senior management to decide whether the model should be used to automatically classify records.\\nRecord Classification Model Analysis and Improvement\\nAll of the projects above rely on our ability to predict the record schedule for a document based on its text and potentially some metadata about the origin of the document. The method currently used by the ECMS team leverages NLP modeling through DeepDetect. We will work to evaluate the model trained through DeepDetect and improve on it by testing other state of the art models. We will also take other steps to improve the model, by restricting the codes the model needs to learn based on requirements from NRMP, adding business logic to classify records where possible, and improving the processes for creating and managing training data. \\nPATT Upload \\n\\tThe PATT tool is a crucial component in EPAs digitization efforts. As paper records are digitized, they need to be uploaded into the ECMs system. We will need to provide a temporary file storage system in AWS S3 which allows files to be stored while they are still being validated by records management personnel. After records are validated, they will be moved to permanent storage in ECMS. \\nEnhanced Search Functionality\\n\\tWithin ECMS and across EPA, it is important to have effective methods to search documents. Open source keyword-based search is implemented in Elasticsearch. Elasticsearch can be further enhanced with vector/semantic based search by leveraging modern NLP models such as GPT and BERT. We will apply these methods to create search capabilities in ECMS, and leverage what we learn to create flexible ways to add search to other EPA systems. \\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tika_req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTika_endpoint = \"https://ecms-cis-tika-prod.edap-cluster.com/tika\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
